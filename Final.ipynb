{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\AppData\\Local\\Continuum\\Anaconda2\\envs\\TensorFlow\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    with open(file_name, encoding='utf-8') as f:\n",
    "        data = []\n",
    "        data_temp = []\n",
    "        labels = []\n",
    "        labels_temp = []\n",
    "\n",
    "        for line in f.read().splitlines():\n",
    "            if line != '':  \n",
    "                a = line.split('\\t')\n",
    "                data_temp.append(a[0])\n",
    "                labels_temp.append(a[1])\n",
    "            else:\n",
    "                data.append(data_temp)\n",
    "                labels.append(labels_temp)\n",
    "                data_temp = []\n",
    "                labels_temp = []\n",
    "\n",
    "    f.close()\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_no_labels(test_file_name):\n",
    "    with open(test_file_name, encoding='utf-8') as f:\n",
    "        data = []\n",
    "        data_temp = []\n",
    "\n",
    "        for line in f.read().splitlines():\n",
    "            if line != '':  \n",
    "                data_temp.append(line)\n",
    "            else:\n",
    "                data.append(data_temp)\n",
    "                data_temp = []\n",
    "    f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, train_labels = read_file('data/train/train.txt')\n",
    "dev_data, dev_labels = read_file('data/dev/dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@paulwalk'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = read_no_labels('data/test/test.nolabels.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read external sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"data/train/eng.list\", encoding='utf-8') as f:\n",
    "    eng_data = []\n",
    "    eng_labels = []\n",
    "\n",
    "    for line in f.read().splitlines():\n",
    "        if line != '':  \n",
    "            temp = line.split(' ')\n",
    "            eng_data.append(temp[1:])\n",
    "            eng_labels.append(['B'] + ['I'] * (len(temp)-2))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_vec(word):\n",
    "    try:\n",
    "        return model[word]\n",
    "    except KeyError:\n",
    "        return ['NULL']*300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS & Chunk tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grammar= r\"\"\"\n",
    "  NP: {<DT|JJ|NN.*>+}          # Chunk sequences of DT, JJ, NN\n",
    "  PP: {<IN><NP>}               # Chunk prepositions followed by NP\n",
    "  VP: {<VB.*><NP|PP|CLAUSE>+$} # Chunk verbs and their arguments\n",
    "  CLAUSE: {<NP><VP>}           # Chunk NP, VP\n",
    "  \"\"\"\n",
    "cp=nltk.RegexpParser(grammar);\n",
    "\n",
    "def chunck_tag(sentence):\n",
    "    tree = cp.parse(sentence)\n",
    "    return nltk.chunk.tree2conlltags(tree.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = [chunck_tag(nltk.pos_tag(train_data[i])) for i in range(len(train_data))]\n",
    "dev_data = [chunck_tag(nltk.pos_tag(dev_data[i])) for i in range(len(dev_data))]\n",
    "test_data = [chunck_tag(nltk.pos_tag(test_data[i])) for i in range(len(test_data))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Word2Features(sentence, pos):\n",
    "    features = {}\n",
    "    features.update(current_word_features(sentence[pos][0]))\n",
    "    features.update(w2vfeatuers(sentence[pos][0]))\n",
    "    if pos > 0:\n",
    "        features.update(prev_word_features(sentence[pos-1][0]))\n",
    "    else:\n",
    "        features.update(begin_of_sentence())\n",
    "    \n",
    "    if pos < len(sentence)-1:\n",
    "        features.update(next_word_features(sentence[pos+1][0]))\n",
    "    else:\n",
    "        features.update(end_of_sentence())\n",
    "        \n",
    "    features.update(tag_features(sentence,pos))\n",
    "#     features.update(chunk_features(sentence,pos))\n",
    "    return features\n",
    "\n",
    "def w2vfeatuers(word):\n",
    "    w2vfeatures = {}\n",
    "    for index, letter in enumerate(get_word_vec(word)):\n",
    "        w2vfeatures.update({'wv_value'+str(index): letter})\n",
    "    return w2vfeatures\n",
    "\n",
    "def current_word_features(word):\n",
    "    return {\n",
    "        'bias': 1.0,\n",
    "        'lower': word.lower(),\n",
    "        'suffix_4': word[-4:],\n",
    "        'suffix_3': word[-3:],\n",
    "        'suffix_2': word[-2:],\n",
    "        'isupper': word.isupper(),\n",
    "        'istitle': word.istitle(),\n",
    "        'isdigit': word.isdigit(),\n",
    "    }\n",
    "\n",
    "\n",
    "def prev_word_features(word):\n",
    "    return {\n",
    "        'prev_lower': word.lower(),\n",
    "        'prev_istitle': word.istitle(),\n",
    "        'prev_isupper': word.isupper(),\n",
    "    }\n",
    "\n",
    "def next_word_features(word):\n",
    "    return {\n",
    "        'next_lower': word.lower(),\n",
    "        'next_istitle': word.istitle(),\n",
    "        'next_isupper': word.isupper(),\n",
    "    }\n",
    "\n",
    "def tag_features(sentence, pos):\n",
    "    pos_features = {'pos[0]': sentence[pos][1]}\n",
    "    prev_prev_pos_tag = sentence[pos-2][1] if pos > 1 else 'START'\n",
    "    prev_pos_tag = sentence[pos-1][1] if pos > 0 else 'START'\n",
    "    next_pos_tag = sentence[pos+1][1] if pos < len(sentence)-1 else 'END'\n",
    "    next_next_pos_tag = sentence[pos+2][1] if pos < len(sentence)-2 else 'END'\n",
    "    pos_features.update({\n",
    "#         'pos[-2]': prev_prev_pos_tag,\n",
    "#         'pos[-1]': prev_pos_tag,\n",
    "#         'pos[+1]': next_pos_tag,\n",
    "#         'pos[+2]': next_next_pos_tag,\n",
    "        'pos[-2]|pos[-1]': prev_prev_pos_tag + '|' + prev_pos_tag,\n",
    "        'pos[-1]|pos[0]': prev_pos_tag + '|' + sentence[pos][1],\n",
    "        'pos[0]|pos[+1]': sentence[pos][1] + '|' + next_pos_tag,\n",
    "        'pos[+1]|pos[+2]': next_pos_tag + '|' + next_next_pos_tag,\n",
    "#         'pos[-2]|pos[-1]|pos[0]': prev_prev_pos_tag + '|' + prev_pos_tag + '|' + sentence[pos][1],\n",
    "#         'pos[-1]|pos[0]|pos[+1]': prev_pos_tag + '|' + sentence[pos][1] + '|' + next_pos_tag,\n",
    "#         'pos[0]|pos[+1]|pos[+2]': sentence[pos][1] + '|' + next_pos_tag + '|' + next_next_pos_tag,        \n",
    "    })\n",
    "    return pos_features\n",
    "\n",
    "def chunk_features(sentence, pos):\n",
    "    chunk_features = {'chunk[0]': sentence[pos][2]}\n",
    "    prev_chunk_tag = sentence[pos-1][2] if pos > 0 else 'NULL'\n",
    "    next_chunk_tag = sentence[pos+1][2] if pos < len(sentence)-1 else 'NULL'\n",
    "    chunk_features.update({\n",
    "        'chunk[-1]': prev_chunk_tag,\n",
    "        'chunk[+1]': next_chunk_tag,\n",
    "        'chunk[-1]|chunk[0]': prev_chunk_tag + '|' + sentence[pos][2],\n",
    "        'chunk[0]|chunk[+1]': sentence[pos][2] + '|' + next_chunk_tag,\n",
    "    })\n",
    "    return chunk_features\n",
    "\n",
    "def begin_of_sentence():\n",
    "    return {'BOS': True}\n",
    "\n",
    "def end_of_sentence():\n",
    "    return {'EOS': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = [[Word2Features(s, pos) for pos in range(len(s))] for s in train_data]\n",
    "y_train = train_labels\n",
    "\n",
    "X_dev = [[Word2Features(s, pos) for pos in range(len(s))] for s in dev_data]\n",
    "y_dev = dev_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BOS': True,\n",
       " 'bias': 1.0,\n",
       " 'isdigit': False,\n",
       " 'istitle': False,\n",
       " 'isupper': False,\n",
       " 'lower': '@paulwalk',\n",
       " 'next_istitle': True,\n",
       " 'next_isupper': False,\n",
       " 'next_lower': 'it',\n",
       " 'pos[+1]': 'PRP',\n",
       " 'pos[+1]|pos[+2]': 'PRP|VBZ',\n",
       " 'pos[+2]': 'VBZ',\n",
       " 'pos[-1]': 'START',\n",
       " 'pos[-1]|pos[0]': 'START|VB',\n",
       " 'pos[-2]': 'START',\n",
       " 'pos[-2]|pos[-1]': 'START|START',\n",
       " 'pos[0]': 'VB',\n",
       " 'pos[0]|pos[+1]': 'VB|PRP',\n",
       " 'wv_value0': 'NULL',\n",
       " 'wv_value1': 'NULL',\n",
       " 'wv_value10': 'NULL',\n",
       " 'wv_value100': 'NULL',\n",
       " 'wv_value101': 'NULL',\n",
       " 'wv_value102': 'NULL',\n",
       " 'wv_value103': 'NULL',\n",
       " 'wv_value104': 'NULL',\n",
       " 'wv_value105': 'NULL',\n",
       " 'wv_value106': 'NULL',\n",
       " 'wv_value107': 'NULL',\n",
       " 'wv_value108': 'NULL',\n",
       " 'wv_value109': 'NULL',\n",
       " 'wv_value11': 'NULL',\n",
       " 'wv_value110': 'NULL',\n",
       " 'wv_value111': 'NULL',\n",
       " 'wv_value112': 'NULL',\n",
       " 'wv_value113': 'NULL',\n",
       " 'wv_value114': 'NULL',\n",
       " 'wv_value115': 'NULL',\n",
       " 'wv_value116': 'NULL',\n",
       " 'wv_value117': 'NULL',\n",
       " 'wv_value118': 'NULL',\n",
       " 'wv_value119': 'NULL',\n",
       " 'wv_value12': 'NULL',\n",
       " 'wv_value120': 'NULL',\n",
       " 'wv_value121': 'NULL',\n",
       " 'wv_value122': 'NULL',\n",
       " 'wv_value123': 'NULL',\n",
       " 'wv_value124': 'NULL',\n",
       " 'wv_value125': 'NULL',\n",
       " 'wv_value126': 'NULL',\n",
       " 'wv_value127': 'NULL',\n",
       " 'wv_value128': 'NULL',\n",
       " 'wv_value129': 'NULL',\n",
       " 'wv_value13': 'NULL',\n",
       " 'wv_value130': 'NULL',\n",
       " 'wv_value131': 'NULL',\n",
       " 'wv_value132': 'NULL',\n",
       " 'wv_value133': 'NULL',\n",
       " 'wv_value134': 'NULL',\n",
       " 'wv_value135': 'NULL',\n",
       " 'wv_value136': 'NULL',\n",
       " 'wv_value137': 'NULL',\n",
       " 'wv_value138': 'NULL',\n",
       " 'wv_value139': 'NULL',\n",
       " 'wv_value14': 'NULL',\n",
       " 'wv_value140': 'NULL',\n",
       " 'wv_value141': 'NULL',\n",
       " 'wv_value142': 'NULL',\n",
       " 'wv_value143': 'NULL',\n",
       " 'wv_value144': 'NULL',\n",
       " 'wv_value145': 'NULL',\n",
       " 'wv_value146': 'NULL',\n",
       " 'wv_value147': 'NULL',\n",
       " 'wv_value148': 'NULL',\n",
       " 'wv_value149': 'NULL',\n",
       " 'wv_value15': 'NULL',\n",
       " 'wv_value150': 'NULL',\n",
       " 'wv_value151': 'NULL',\n",
       " 'wv_value152': 'NULL',\n",
       " 'wv_value153': 'NULL',\n",
       " 'wv_value154': 'NULL',\n",
       " 'wv_value155': 'NULL',\n",
       " 'wv_value156': 'NULL',\n",
       " 'wv_value157': 'NULL',\n",
       " 'wv_value158': 'NULL',\n",
       " 'wv_value159': 'NULL',\n",
       " 'wv_value16': 'NULL',\n",
       " 'wv_value160': 'NULL',\n",
       " 'wv_value161': 'NULL',\n",
       " 'wv_value162': 'NULL',\n",
       " 'wv_value163': 'NULL',\n",
       " 'wv_value164': 'NULL',\n",
       " 'wv_value165': 'NULL',\n",
       " 'wv_value166': 'NULL',\n",
       " 'wv_value167': 'NULL',\n",
       " 'wv_value168': 'NULL',\n",
       " 'wv_value169': 'NULL',\n",
       " 'wv_value17': 'NULL',\n",
       " 'wv_value170': 'NULL',\n",
       " 'wv_value171': 'NULL',\n",
       " 'wv_value172': 'NULL',\n",
       " 'wv_value173': 'NULL',\n",
       " 'wv_value174': 'NULL',\n",
       " 'wv_value175': 'NULL',\n",
       " 'wv_value176': 'NULL',\n",
       " 'wv_value177': 'NULL',\n",
       " 'wv_value178': 'NULL',\n",
       " 'wv_value179': 'NULL',\n",
       " 'wv_value18': 'NULL',\n",
       " 'wv_value180': 'NULL',\n",
       " 'wv_value181': 'NULL',\n",
       " 'wv_value182': 'NULL',\n",
       " 'wv_value183': 'NULL',\n",
       " 'wv_value184': 'NULL',\n",
       " 'wv_value185': 'NULL',\n",
       " 'wv_value186': 'NULL',\n",
       " 'wv_value187': 'NULL',\n",
       " 'wv_value188': 'NULL',\n",
       " 'wv_value189': 'NULL',\n",
       " 'wv_value19': 'NULL',\n",
       " 'wv_value190': 'NULL',\n",
       " 'wv_value191': 'NULL',\n",
       " 'wv_value192': 'NULL',\n",
       " 'wv_value193': 'NULL',\n",
       " 'wv_value194': 'NULL',\n",
       " 'wv_value195': 'NULL',\n",
       " 'wv_value196': 'NULL',\n",
       " 'wv_value197': 'NULL',\n",
       " 'wv_value198': 'NULL',\n",
       " 'wv_value199': 'NULL',\n",
       " 'wv_value2': 'NULL',\n",
       " 'wv_value20': 'NULL',\n",
       " 'wv_value200': 'NULL',\n",
       " 'wv_value201': 'NULL',\n",
       " 'wv_value202': 'NULL',\n",
       " 'wv_value203': 'NULL',\n",
       " 'wv_value204': 'NULL',\n",
       " 'wv_value205': 'NULL',\n",
       " 'wv_value206': 'NULL',\n",
       " 'wv_value207': 'NULL',\n",
       " 'wv_value208': 'NULL',\n",
       " 'wv_value209': 'NULL',\n",
       " 'wv_value21': 'NULL',\n",
       " 'wv_value210': 'NULL',\n",
       " 'wv_value211': 'NULL',\n",
       " 'wv_value212': 'NULL',\n",
       " 'wv_value213': 'NULL',\n",
       " 'wv_value214': 'NULL',\n",
       " 'wv_value215': 'NULL',\n",
       " 'wv_value216': 'NULL',\n",
       " 'wv_value217': 'NULL',\n",
       " 'wv_value218': 'NULL',\n",
       " 'wv_value219': 'NULL',\n",
       " 'wv_value22': 'NULL',\n",
       " 'wv_value220': 'NULL',\n",
       " 'wv_value221': 'NULL',\n",
       " 'wv_value222': 'NULL',\n",
       " 'wv_value223': 'NULL',\n",
       " 'wv_value224': 'NULL',\n",
       " 'wv_value225': 'NULL',\n",
       " 'wv_value226': 'NULL',\n",
       " 'wv_value227': 'NULL',\n",
       " 'wv_value228': 'NULL',\n",
       " 'wv_value229': 'NULL',\n",
       " 'wv_value23': 'NULL',\n",
       " 'wv_value230': 'NULL',\n",
       " 'wv_value231': 'NULL',\n",
       " 'wv_value232': 'NULL',\n",
       " 'wv_value233': 'NULL',\n",
       " 'wv_value234': 'NULL',\n",
       " 'wv_value235': 'NULL',\n",
       " 'wv_value236': 'NULL',\n",
       " 'wv_value237': 'NULL',\n",
       " 'wv_value238': 'NULL',\n",
       " 'wv_value239': 'NULL',\n",
       " 'wv_value24': 'NULL',\n",
       " 'wv_value240': 'NULL',\n",
       " 'wv_value241': 'NULL',\n",
       " 'wv_value242': 'NULL',\n",
       " 'wv_value243': 'NULL',\n",
       " 'wv_value244': 'NULL',\n",
       " 'wv_value245': 'NULL',\n",
       " 'wv_value246': 'NULL',\n",
       " 'wv_value247': 'NULL',\n",
       " 'wv_value248': 'NULL',\n",
       " 'wv_value249': 'NULL',\n",
       " 'wv_value25': 'NULL',\n",
       " 'wv_value250': 'NULL',\n",
       " 'wv_value251': 'NULL',\n",
       " 'wv_value252': 'NULL',\n",
       " 'wv_value253': 'NULL',\n",
       " 'wv_value254': 'NULL',\n",
       " 'wv_value255': 'NULL',\n",
       " 'wv_value256': 'NULL',\n",
       " 'wv_value257': 'NULL',\n",
       " 'wv_value258': 'NULL',\n",
       " 'wv_value259': 'NULL',\n",
       " 'wv_value26': 'NULL',\n",
       " 'wv_value260': 'NULL',\n",
       " 'wv_value261': 'NULL',\n",
       " 'wv_value262': 'NULL',\n",
       " 'wv_value263': 'NULL',\n",
       " 'wv_value264': 'NULL',\n",
       " 'wv_value265': 'NULL',\n",
       " 'wv_value266': 'NULL',\n",
       " 'wv_value267': 'NULL',\n",
       " 'wv_value268': 'NULL',\n",
       " 'wv_value269': 'NULL',\n",
       " 'wv_value27': 'NULL',\n",
       " 'wv_value270': 'NULL',\n",
       " 'wv_value271': 'NULL',\n",
       " 'wv_value272': 'NULL',\n",
       " 'wv_value273': 'NULL',\n",
       " 'wv_value274': 'NULL',\n",
       " 'wv_value275': 'NULL',\n",
       " 'wv_value276': 'NULL',\n",
       " 'wv_value277': 'NULL',\n",
       " 'wv_value278': 'NULL',\n",
       " 'wv_value279': 'NULL',\n",
       " 'wv_value28': 'NULL',\n",
       " 'wv_value280': 'NULL',\n",
       " 'wv_value281': 'NULL',\n",
       " 'wv_value282': 'NULL',\n",
       " 'wv_value283': 'NULL',\n",
       " 'wv_value284': 'NULL',\n",
       " 'wv_value285': 'NULL',\n",
       " 'wv_value286': 'NULL',\n",
       " 'wv_value287': 'NULL',\n",
       " 'wv_value288': 'NULL',\n",
       " 'wv_value289': 'NULL',\n",
       " 'wv_value29': 'NULL',\n",
       " 'wv_value290': 'NULL',\n",
       " 'wv_value291': 'NULL',\n",
       " 'wv_value292': 'NULL',\n",
       " 'wv_value293': 'NULL',\n",
       " 'wv_value294': 'NULL',\n",
       " 'wv_value295': 'NULL',\n",
       " 'wv_value296': 'NULL',\n",
       " 'wv_value297': 'NULL',\n",
       " 'wv_value298': 'NULL',\n",
       " 'wv_value299': 'NULL',\n",
       " 'wv_value3': 'NULL',\n",
       " 'wv_value30': 'NULL',\n",
       " 'wv_value31': 'NULL',\n",
       " 'wv_value32': 'NULL',\n",
       " 'wv_value33': 'NULL',\n",
       " 'wv_value34': 'NULL',\n",
       " 'wv_value35': 'NULL',\n",
       " 'wv_value36': 'NULL',\n",
       " 'wv_value37': 'NULL',\n",
       " 'wv_value38': 'NULL',\n",
       " 'wv_value39': 'NULL',\n",
       " 'wv_value4': 'NULL',\n",
       " 'wv_value40': 'NULL',\n",
       " 'wv_value41': 'NULL',\n",
       " 'wv_value42': 'NULL',\n",
       " 'wv_value43': 'NULL',\n",
       " 'wv_value44': 'NULL',\n",
       " 'wv_value45': 'NULL',\n",
       " 'wv_value46': 'NULL',\n",
       " 'wv_value47': 'NULL',\n",
       " 'wv_value48': 'NULL',\n",
       " 'wv_value49': 'NULL',\n",
       " 'wv_value5': 'NULL',\n",
       " 'wv_value50': 'NULL',\n",
       " 'wv_value51': 'NULL',\n",
       " 'wv_value52': 'NULL',\n",
       " 'wv_value53': 'NULL',\n",
       " 'wv_value54': 'NULL',\n",
       " 'wv_value55': 'NULL',\n",
       " 'wv_value56': 'NULL',\n",
       " 'wv_value57': 'NULL',\n",
       " 'wv_value58': 'NULL',\n",
       " 'wv_value59': 'NULL',\n",
       " 'wv_value6': 'NULL',\n",
       " 'wv_value60': 'NULL',\n",
       " 'wv_value61': 'NULL',\n",
       " 'wv_value62': 'NULL',\n",
       " 'wv_value63': 'NULL',\n",
       " 'wv_value64': 'NULL',\n",
       " 'wv_value65': 'NULL',\n",
       " 'wv_value66': 'NULL',\n",
       " 'wv_value67': 'NULL',\n",
       " 'wv_value68': 'NULL',\n",
       " 'wv_value69': 'NULL',\n",
       " 'wv_value7': 'NULL',\n",
       " 'wv_value70': 'NULL',\n",
       " 'wv_value71': 'NULL',\n",
       " 'wv_value72': 'NULL',\n",
       " 'wv_value73': 'NULL',\n",
       " 'wv_value74': 'NULL',\n",
       " 'wv_value75': 'NULL',\n",
       " 'wv_value76': 'NULL',\n",
       " 'wv_value77': 'NULL',\n",
       " 'wv_value78': 'NULL',\n",
       " 'wv_value79': 'NULL',\n",
       " 'wv_value8': 'NULL',\n",
       " 'wv_value80': 'NULL',\n",
       " 'wv_value81': 'NULL',\n",
       " 'wv_value82': 'NULL',\n",
       " 'wv_value83': 'NULL',\n",
       " 'wv_value84': 'NULL',\n",
       " 'wv_value85': 'NULL',\n",
       " 'wv_value86': 'NULL',\n",
       " 'wv_value87': 'NULL',\n",
       " 'wv_value88': 'NULL',\n",
       " 'wv_value89': 'NULL',\n",
       " 'wv_value9': 'NULL',\n",
       " 'wv_value90': 'NULL',\n",
       " 'wv_value91': 'NULL',\n",
       " 'wv_value92': 'NULL',\n",
       " 'wv_value93': 'NULL',\n",
       " 'wv_value94': 'NULL',\n",
       " 'wv_value95': 'NULL',\n",
       " 'wv_value96': 'NULL',\n",
       " 'wv_value97': 'NULL',\n",
       " 'wv_value98': 'NULL',\n",
       " 'wv_value99': 'NULL'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_test = [[Word2Features(s, pos) for pos in range(len(s))] for s in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego\\AppData\\Local\\Continuum\\Anaconda2\\envs\\TensorFlow\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Diego\\AppData\\Local\\Continuum\\Anaconda2\\envs\\TensorFlow\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define fixed parameters and parameters to search\n",
    "crf_CV = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.05),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score, \n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf_CV, params_space, \n",
    "                        cv=3, \n",
    "                        verbose=1, \n",
    "                        n_jobs=-1, \n",
    "                        n_iter=50, \n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crf_final = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.01, \n",
    "    c2=0.01, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'I']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf_final.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99434308860544485"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = crf_final.predict(X_train)\n",
    "metrics.flat_f1_score(y_train, y_train_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run on the Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59239858140628943"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dev_pred = crf_final.predict(X_dev)\n",
    "metrics.flat_f1_score(y_dev, y_dev_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B      0.801     0.519     0.630       459\n",
      "          I      0.667     0.440     0.530       273\n",
      "\n",
      "avg / total      0.751     0.489     0.592       732\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.flat_classification_report(\n",
    "    y_dev, y_dev_pred, labels=labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 510 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test_pred = crf_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_output(pred, outputfile):\n",
    "    f = open(outputfile,'w')\n",
    "    for label_sentence in pred:\n",
    "        for label_word in label_sentence:\n",
    "            f.write(label_word + '\\n')\n",
    "        f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generate_output(y_dev_pred, \"output-dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "6.567432 B        lower:twitter\n",
      "3.792135 B        lower:facebook\n",
      "2.826828 B        lower:pope\n",
      "2.580548 B        lower:youtube\n",
      "2.514104 B        suffix_3:mas\n",
      "2.424522 B        lower:ipad\n",
      "2.371110 B        lower:iphone\n",
      "2.160594 O        next_lower:bless\n",
      "2.149650 I        prev_lower:fashion\n",
      "2.096999 B        lower:ipod\n",
      "2.092677 B        suffix_4:alds\n",
      "1.999379 B        lower:taylor\n",
      "1.999376 B        prev_lower:go\n",
      "1.989796 B        lower:uk\n",
      "1.939972 O        lower:and\n",
      "1.896921 B        lower:steve\n",
      "1.896921 B        suffix_4:teve\n",
      "1.877813 B        suffix_4:enny\n",
      "1.870439 B        suffix_2:GP\n",
      "1.849041 I        lower:day\n",
      "1.838438 O        lower:prison\n",
      "1.820803 O        prev_lower:gaye\n",
      "1.802747 B        lower:chicago\n",
      "1.797612 I        prev_lower:dj\n",
      "1.791227 O        lower:free\n",
      "1.762508 I        suffix_2:rk\n",
      "1.753413 I        prev_lower:stylez\n",
      "1.753413 I        next_lower:a.k.a.\n",
      "1.740830 B        suffix_2:DA\n",
      "1.725471 O        BOS\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top negative:\n",
      "-1.371758 O        pos[+1]|pos[+2]:FW|NNP\n",
      "-1.391221 O        lower:itunes\n",
      "-1.391221 O        suffix_4:unes\n",
      "-1.394320 O        suffix_3:lds\n",
      "-1.410080 O        suffix_2:na\n",
      "-1.416634 O        pos[0]:NNPS\n",
      "-1.420462 O        next_lower:full\n",
      "-1.429323 O        prev_lower:then\n",
      "-1.430705 O        pos[0]|pos[+1]|pos[+2]:NN|,|CC\n",
      "-1.434475 O        next_lower:was\n",
      "-1.518657 O        istitle\n",
      "-1.524179 B        pos[-1]|pos[0]|pos[+1]:CC|NNP|NNP\n",
      "-1.534428 O        pos[+1]|pos[+2]:.|JJ\n",
      "-1.558676 O        suffix_2:LE\n",
      "-1.571161 O        pos[-1]|pos[0]|pos[+1]:.|NNS|.\n",
      "-1.583378 B        prev_istitle\n",
      "-1.591711 O        suffix_2:ix\n",
      "-1.609285 O        next_lower:live\n",
      "-1.628820 O        suffix_4:pope\n",
      "-1.637103 O        suffix_3:Pad\n",
      "-1.648974 O        suffix_4:eber\n",
      "-1.651023 B        suffix_2:ay\n",
      "-1.654816 O        next_lower:fans\n",
      "-1.663851 O        suffix_3:ube\n",
      "-1.717274 O        suffix_2:HD\n",
      "-1.719929 O        next_lower:!!!!!!!\n",
      "-1.838786 O        suffix_2:GP\n",
      "-1.859041 O        suffix_3:ndo\n",
      "-1.911576 O        suffix_2:ka\n",
      "-1.933838 O        suffix_4:wood\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [TensorFlow]",
   "language": "python",
   "name": "Python [TensorFlow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
